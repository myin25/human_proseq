{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8bf6af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bpnetlite.io import extract_loci\n",
    "from bpnetlite.performance import calculate_performance_measures\n",
    "\n",
    "timestamp = \"2023-06-14_10:16:58\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca467d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/users/myin25/projects/human_proseq/data/coPRO_3prime/K562/'\n",
    "\n",
    "peaks = root + 'peaks_fold1_val.bed.gz'\n",
    "seqs = '/users/myin25/projects/human_proseq/refs/hg38.fasta'\n",
    "signals = [root + '3prime.pos.bigWig', root + '3prime.neg.bigWig']\n",
    "controls = None\n",
    "\n",
    "valid_chroms = ['chr{}'.format(i) for i in range(0, 23)]\n",
    "valid_chroms.append('chrX')\n",
    "valid_chroms.append('chrY')\n",
    "\n",
    "model_directory = '/users/myin25/projects/human_proseq/models'\n",
    "model_path = model_directory + '/{}.final.torch'.format(timestamp)\n",
    "\n",
    "val_save_dir = root + \"model_out/\"\n",
    "os.makedirs(val_save_dir, exist_ok=True)\n",
    "\n",
    "pred_counts_path = val_save_dir + timestamp + \"_val.counts.npy\"\n",
    "pred_profiles_path = val_save_dir + timestamp + \"_val.profs.npy\"\n",
    "metrics_path = val_save_dir + timestamp + \"_metrics.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa894261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41716/4104606860.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_sequences = torch.tensor(val_sequences, dtype=torch.float32).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3699, 1, 1)\n",
      "torch.Size([3699, 1, 1])\n",
      "torch.Size([3699, 1, 1000, 2])\n",
      "torch.Size([3699, 1, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[200, 200, 1000]}, size=[200, 1]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_profile\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_counts\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 46\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_performance_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_profile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m81\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmooth_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m metrics_to_save \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjsd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile_pearson\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     51\u001b[0m metrics_dict \u001b[38;5;241m=\u001b[39m { metric : \u001b[38;5;28mlist\u001b[39m(vals\u001b[38;5;241m.\u001b[39msqueeze()) \u001b[38;5;28;01mfor\u001b[39;00m metric, vals \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics_to_save }\n",
      "File \u001b[0;32m~/miniconda/envs/copro/lib/python3.9/site-packages/bpnetlite/performance.py:311\u001b[0m, in \u001b[0;36mcalculate_performance_measures\u001b[0;34m(logps, true_counts, pred_log_counts, kernel_sigma, kernel_width, smooth_true, smooth_predictions, measures)\u001b[0m\n\u001b[1;32m    308\u001b[0m measures_ \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m measures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile_mnll\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m measures: \n\u001b[0;32m--> 311\u001b[0m     measures_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile_mnll\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_smoothed_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMNLLLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msmooth_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmooth_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m measures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile_jsd\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m measures: \n\u001b[1;32m    317\u001b[0m     measures_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile_jsd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m batched_smoothed_function(logps\u001b[38;5;241m=\u001b[39mlogps, \n\u001b[1;32m    318\u001b[0m         true_counts\u001b[38;5;241m=\u001b[39mtrue_counts, f\u001b[38;5;241m=\u001b[39mjensen_shannon_distance, \n\u001b[1;32m    319\u001b[0m         smooth_predictions\u001b[38;5;241m=\u001b[39msmooth_predictions, smooth_true\u001b[38;5;241m=\u001b[39msmooth_true, \n\u001b[1;32m    320\u001b[0m         kernel_sigma\u001b[38;5;241m=\u001b[39mkernel_sigma, kernel_width\u001b[38;5;241m=\u001b[39mkernel_width)\n",
      "File \u001b[0;32m~/miniconda/envs/copro/lib/python3.9/site-packages/bpnetlite/performance.py:129\u001b[0m, in \u001b[0;36mbatched_smoothed_function\u001b[0;34m(logps, true_counts, f, smooth_predictions, smooth_true, kernel_sigma, kernel_width, exponentiate_logps, batch_size)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m smooth_true:\n\u001b[1;32m    127\u001b[0m         true_counts_ \u001b[38;5;241m=\u001b[39m smooth_gaussian1d(true_counts_, kernel_sigma, kernel_width)\n\u001b[0;32m--> 129\u001b[0m     results[start:end] \u001b[38;5;241m=\u001b[39m f(logps_, true_counts_) \n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[200, 200, 1000]}, size=[200, 1]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "    \n",
    "# Load Data\n",
    "val_sequences, val_profs = extract_loci(peaks, seqs, signals, controls, chroms=valid_chroms, max_jitter=0)\n",
    "\n",
    "# Predict on Validation Set\n",
    "with torch.no_grad():\n",
    "    val_sequences = torch.tensor(val_sequences, dtype=torch.float32).cuda()\n",
    "    pred_profile, pred_counts = model.predict(val_sequences)\n",
    "    \n",
    "    \n",
    "# Save Predictions\n",
    "numpy.save(pred_profiles_path, pred_profile)\n",
    "numpy.save(pred_counts_path, pred_counts)\n",
    "\n",
    "\n",
    "# re-format arrays for performance metrics code\n",
    "\n",
    "#val_profs = val_profs.reshape(val_profs.shape[0], -1)\n",
    "val_profs = numpy.swapaxes(numpy.expand_dims(val_profs, 1), 2, 3)\n",
    "val_counts = val_profs.sum(axis=2)\n",
    "val_counts = numpy.sum(val_counts, axis=2)\n",
    "val_counts = val_counts[...,None]\n",
    "print(val_counts.shape)\n",
    "\n",
    "\n",
    "#pred_profile = pred_profile.reshape(pred_profile.shape[0], -1)\n",
    "pred_profile = numpy.swapaxes(numpy.expand_dims(pred_profile, 1),2,3)\n",
    "pred_counts = numpy.expand_dims(pred_counts, 1)\n",
    "# pred_log_counts = log1p(pred_counts)\n",
    "\n",
    "# convert everything to tensors\n",
    "val_counts = torch.tensor(val_counts, dtype=torch.float32)\n",
    "pred_profile = torch.tensor(pred_profile, dtype=torch.float32)\n",
    "pred_counts = torch.tensor(pred_counts, dtype=torch.float32)\n",
    "\n",
    "# Compute Performance Metrics\n",
    "\n",
    "print(val_counts.shape)\n",
    "print(pred_profile.shape)\n",
    "print(pred_counts.shape)\n",
    "\n",
    "metrics = calculate_performance_measures(pred_profile, val_counts, pred_counts,\n",
    "    kernel_sigma=7, kernel_width=81, smooth_true=False, \n",
    "    smooth_predictions=False, measures=None)\n",
    "\n",
    "metrics_to_save = [\"nll\", \"jsd\", \"profile_pearson\"]\n",
    "metrics_dict = { metric : list(vals.squeeze()) for metric, vals in metrics.items() if metric in metrics_to_save }\n",
    "metrics_df = pandas.DataFrame(metrics_dict)\n",
    "metrics_df.to_csv(metrics_path, sep=\"\\t\", index=False)\n",
    "\n",
    "metrics_to_report = [\"nll\", \"jsd\", \"profile_pearson\", \"count_pearson\", \"count_mse\"]\n",
    "metrics_summary = [str(metrics[metric].mean()) for metric in metrics_to_report] \n",
    "\n",
    "print(\"Peaks: \" + peaks)\n",
    "print(\"Model: \" + model_path)\n",
    "print(\"Pred_profiles: \" + pred_profiles_path)\n",
    "print(\"Pred_counts: \" + pred_counts_path)\n",
    "mean_metrics = [\"Mean \" + metric + \": \" + val for metric, val in zip(metrics_to_report, metrics_summary)]\n",
    "print(\"\\n\".join(mean_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, true_profiles = extract_loci(peaks, seqs, signals, controls, chroms=valid_chroms, max_jitter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_save_dir = proj_root + \"model_out/\" + expt_name + \"/\"\n",
    "pred_counts_path = val_save_dir + timestamp + \"_val.counts.npy\"\n",
    "pred_profiles_path = val_save_dir + timestamp + \"_val.profs.npy\"\n",
    "metrics_path = val_save_dir + timestamp + \"_metrics.tsv\"\n",
    "\n",
    "true_counts = true_profiles.sum(axis=2)\n",
    "true_logcounts = numpy.log1p(true_counts)\n",
    "pred_logcounts = numpy.load(pred_counts_path).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c25a4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3699, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(val_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee2ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:copro] *",
   "language": "python",
   "name": "conda-env-copro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
